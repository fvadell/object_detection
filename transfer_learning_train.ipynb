{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "from model import SSD300, MultiBoxLoss, PredictionConvolutions\n",
    "from datasets import PascalVOCDataset\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './'  # folder with data files\n",
    "keep_difficult = True  # use objects considered difficult to detect?\n",
    "\n",
    "# Model parameters\n",
    "n_classes = len(label_map)  # number of different types of objects\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'piso_parquet': 1, 'piso_ceramica': 2, 'background': 0},\n",
       " 3,\n",
       " device(type='cuda'))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map, n_classes, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning parameters\n",
    "checkpoint = None  # path to model checkpoint, None if none\n",
    "checkpoint = './checkpoints/checkpoint_ssd300.pth.tar'\n",
    "batch_size = 2  # batch size\n",
    "iterations = 120000  # number of iterations to train\n",
    "workers = 4  # number of workers for loading data in the DataLoader\n",
    "print_freq = 200  # print training status every __ batches\n",
    "lr = 1e-3  # learning rate\n",
    "decay_lr_at = [80000, 100000]  # decay learning rate after these many iterations\n",
    "decay_lr_to = 0.1  # decay learning rate to this fraction of the existing learning rate\n",
    "momentum = 0.9  # momentum\n",
    "weight_decay = 5e-4  # weight decay\n",
    "grad_clip = None  # clip if gradients are exploding, which may happen at larger batch sizes (sometimes at 32) - you will recognize it by a sorting error in the MuliBox loss calculation\n",
    "\n",
    "cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Training.\n",
    "    \"\"\"\n",
    "    global start_epoch, label_map, epoch, checkpoint, decay_lr_at\n",
    "\n",
    "    # Initialize model or load checkpoint\n",
    "    if checkpoint is None:\n",
    "        start_epoch = 0\n",
    "        model = SSD300(n_classes=n_classes)\n",
    "        print('\\nLoaded new SSD300 model')\n",
    "        checkpoint = []\n",
    "\n",
    "    else: # cargo checkpoint (modelo pre entrenado)\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print('\\nLoaded checkpoint from epoch %d.\\n' % start_epoch)\n",
    "        model = checkpoint['model']\n",
    "        model.pred_convs = PredictionConvolutions(n_classes) # Cambio las capas predictivas\n",
    "        \n",
    "        # Frizo todas las capas\n",
    "        for child in model.children():\n",
    "            for layer in child.children():\n",
    "                for i in layer.parameters():\n",
    "                    i.requires_grad = False\n",
    "    \n",
    "        # Desfrizo las de la capa predictiva\n",
    "        print(\"\\n\")\n",
    "        for l in model.pred_convs.children():\n",
    "            for p in l.parameters():\n",
    "                p.requires_grad = True\n",
    "                print(str(l) + \"<- No Frizada\")\n",
    "                \n",
    "        # Desfrizo las capas en layers\n",
    "        #  conv 4_3, conv 7, conv 8_2, conv 9_2, conv 10_2, conv 11_2 + pred convs\n",
    "        layers = [model.base.conv4_3, model.base.conv7, model.aux_convs.conv8_2, model.aux_convs.conv9_2, model.aux_convs.conv10_2, model.aux_convs.conv11_2]\n",
    "        for l in layers:\n",
    "            for i in l.parameters():\n",
    "                i.requires_grad = True\n",
    "                print(str(l) + \"<- No Frizada\")\n",
    "\n",
    "    if 'optimizer' not in checkpoint:\n",
    "        print(\"Optimizer no encontrado. Generando uno...\")\n",
    "        # Initialize the optimizer, with twice the default learning rate for biases, as in the original Caffe repo\n",
    "        biases = list()\n",
    "        not_biases = list()\n",
    "        for param_name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if param_name.endswith('.bias'):\n",
    "                    biases.append(param) # Separo los parametros que son de bias de los que no\n",
    "                else:                    # porque vamos a aplicarles learning rates distintos\n",
    "                    not_biases.append(param)\n",
    "        optimizer = torch.optim.SGD(params=[{'params': biases, 'lr': 2 * lr}, {'params': not_biases}],\n",
    "                                    lr=lr, momentum=momentum, weight_decay=weight_decay) # Aca creamos el optimizador y\n",
    "                                                                                         # y aplicamos los distintos LR\n",
    "    # Move to default device\n",
    "    print(\"Pasando el modelo a \", device)\n",
    "    model = model.to(device)\n",
    "    criterion = MultiBoxLoss(priors_cxcy=model.priors_cxcy).to(device)\n",
    "\n",
    "    # Custom dataloaders\n",
    "    print(\"Seteando dataset y dataloader\")\n",
    "    train_dataset = PascalVOCDataset(data_folder,\n",
    "                                     split='train',\n",
    "                                     keep_difficult=keep_difficult)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                               collate_fn=train_dataset.collate_fn, num_workers=workers,\n",
    "                                               pin_memory=True)  # note that we're passing the collate function here\n",
    "\n",
    "    # Calculate total number of epochs to train and the epochs to decay learning rate at (i.e. convert iterations to epochs)\n",
    "    # To convert iterations to epochs, divide iterations by the number of iterations per epoch\n",
    "    # The paper trains for 120,000 iterations with a batch size of 32, decays after 80,000 and 100,000 iterations\n",
    "    epochs = iterations // (len(train_dataset) // 8)\n",
    "    epochs = start_epoch + 150 # Probar\n",
    "    decay_lr_at = [it // (len(train_dataset) // 8) for it in decay_lr_at]\n",
    "\n",
    "    # Epochs\n",
    "    print(\"Arrancando loop de entrenamiento.\\nEpochs: \", epochs)\n",
    "    print(\"start epoch:\", start_epoch)\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        print(\"epoch: \"+ str(epoch) + \"/\" + str(epochs))\n",
    "        # Decay learning rate at particular epochs\n",
    "        if epoch in decay_lr_at:\n",
    "            adjust_learning_rate(optimizer, decay_lr_to)\n",
    "\n",
    "        # One epoch's training\n",
    "        train(train_loader=train_loader,\n",
    "              model=model,\n",
    "              criterion=criterion,\n",
    "              optimizer=optimizer,\n",
    "              epoch=epoch)\n",
    "\n",
    "        # Save checkpoint\n",
    "        #save_checkpoint(epoch, model, optimizer)\n",
    "    return epoch, model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    One epoch's training.\n",
    "\n",
    "    :param train_loader: DataLoader for training data\n",
    "    :param model: model\n",
    "    :param criterion: MultiBox loss\n",
    "    :param optimizer: optimizer\n",
    "    :param epoch: epoch number\n",
    "    \"\"\"\n",
    "    model.train()  # training mode enables dropout\n",
    "\n",
    "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    losses = AverageMeter()  # loss\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Batches\n",
    "    for i, (images, boxes, labels, _) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - start)\n",
    "\n",
    "        # Move to default device\n",
    "        images = images.to(device)  # (batch_size (N), 3, 300, 300)\n",
    "        boxes = [b.to(device) for b in boxes]\n",
    "        labels = [l.to(device) for l in labels]\n",
    "\n",
    "        # Forward prop.\n",
    "        predicted_locs, predicted_scores = model(images)  # (N, 8732, 4), (N, 8732, n_classes)\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(predicted_locs, predicted_scores, boxes, labels)  # scalar\n",
    "\n",
    "        # Backward prop.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients, if necessary\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(optimizer, grad_clip)\n",
    "\n",
    "        # Update model\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        batch_time.update(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Print status\n",
    "        if i % print_freq == 0:\n",
    "            print(predicted_locs.shape)\n",
    "            print(predicted_scores.shape)\n",
    "            \n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(epoch, i, len(train_loader),\n",
    "                                                                  batch_time=batch_time,\n",
    "                                                                  data_time=data_time, loss=losses))\n",
    "    del predicted_locs, predicted_scores, images, boxes, labels  # free some memory since their histories may be stored\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded checkpoint from epoch 232.\n",
      "\n",
      "\n",
      "\n",
      "Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(512, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(512, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<- No Frizada\n",
      "Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))<- No Frizada\n",
      "Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))<- No Frizada\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))<- No Frizada\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))<- No Frizada\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))<- No Frizada\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))<- No Frizada\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))<- No Frizada\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))<- No Frizada\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))<- No Frizada\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))<- No Frizada\n",
      "Optimizer no encontrado. Generando uno...\n",
      "Pasando el modelo a  cuda\n",
      "Seteando dataset y dataloader\n",
      "Arrancando loop de entrenamiento.\n",
      "Epochs:  382\n",
      "start epoch: 232\n",
      "epoch: 232/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [232][0/55]\tBatch Time 2.931 (2.931)\tData Time 2.877 (2.877)\tLoss 9.0053 (9.0053)\t\n",
      "epoch: 233/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [233][0/55]\tBatch Time 2.889 (2.889)\tData Time 2.831 (2.831)\tLoss 4.5993 (4.5993)\t\n",
      "epoch: 234/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [234][0/55]\tBatch Time 2.958 (2.958)\tData Time 2.903 (2.903)\tLoss 5.1697 (5.1697)\t\n",
      "epoch: 235/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [235][0/55]\tBatch Time 3.006 (3.006)\tData Time 2.953 (2.953)\tLoss 4.0615 (4.0615)\t\n",
      "epoch: 236/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [236][0/55]\tBatch Time 2.842 (2.842)\tData Time 2.790 (2.790)\tLoss 3.8509 (3.8509)\t\n",
      "epoch: 237/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [237][0/55]\tBatch Time 2.840 (2.840)\tData Time 2.783 (2.783)\tLoss 4.1432 (4.1432)\t\n",
      "epoch: 238/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [238][0/55]\tBatch Time 2.884 (2.884)\tData Time 2.831 (2.831)\tLoss 4.2590 (4.2590)\t\n",
      "epoch: 239/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [239][0/55]\tBatch Time 2.825 (2.825)\tData Time 2.769 (2.769)\tLoss 3.5617 (3.5617)\t\n",
      "epoch: 240/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [240][0/55]\tBatch Time 2.849 (2.849)\tData Time 2.795 (2.795)\tLoss 3.7008 (3.7008)\t\n",
      "epoch: 241/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [241][0/55]\tBatch Time 2.890 (2.890)\tData Time 2.833 (2.833)\tLoss 2.8204 (2.8204)\t\n",
      "epoch: 242/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [242][0/55]\tBatch Time 2.906 (2.906)\tData Time 2.853 (2.853)\tLoss 2.7335 (2.7335)\t\n",
      "epoch: 243/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [243][0/55]\tBatch Time 2.884 (2.884)\tData Time 2.830 (2.830)\tLoss 3.7773 (3.7773)\t\n",
      "epoch: 244/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [244][0/55]\tBatch Time 3.099 (3.099)\tData Time 3.040 (3.040)\tLoss 3.8791 (3.8791)\t\n",
      "epoch: 245/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [245][0/55]\tBatch Time 2.864 (2.864)\tData Time 2.810 (2.810)\tLoss 3.6695 (3.6695)\t\n",
      "epoch: 246/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [246][0/55]\tBatch Time 2.834 (2.834)\tData Time 2.780 (2.780)\tLoss 3.7735 (3.7735)\t\n",
      "epoch: 247/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [247][0/55]\tBatch Time 2.852 (2.852)\tData Time 2.798 (2.798)\tLoss 2.9727 (2.9727)\t\n",
      "epoch: 248/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [248][0/55]\tBatch Time 2.839 (2.839)\tData Time 2.782 (2.782)\tLoss 4.8090 (4.8090)\t\n",
      "epoch: 249/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [249][0/55]\tBatch Time 2.827 (2.827)\tData Time 2.771 (2.771)\tLoss 2.9677 (2.9677)\t\n",
      "epoch: 250/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [250][0/55]\tBatch Time 2.824 (2.824)\tData Time 2.771 (2.771)\tLoss 2.9505 (2.9505)\t\n",
      "epoch: 251/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [251][0/55]\tBatch Time 2.846 (2.846)\tData Time 2.792 (2.792)\tLoss 3.6807 (3.6807)\t\n",
      "epoch: 252/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [252][0/55]\tBatch Time 2.883 (2.883)\tData Time 2.825 (2.825)\tLoss 3.3233 (3.3233)\t\n",
      "epoch: 253/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [253][0/55]\tBatch Time 2.993 (2.993)\tData Time 2.940 (2.940)\tLoss 3.4917 (3.4917)\t\n",
      "epoch: 254/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [254][0/55]\tBatch Time 3.201 (3.201)\tData Time 3.149 (3.149)\tLoss 3.4378 (3.4378)\t\n",
      "epoch: 255/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [255][0/55]\tBatch Time 2.898 (2.898)\tData Time 2.846 (2.846)\tLoss 2.6442 (2.6442)\t\n",
      "epoch: 256/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [256][0/55]\tBatch Time 2.832 (2.832)\tData Time 2.780 (2.780)\tLoss 3.1341 (3.1341)\t\n",
      "epoch: 257/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [257][0/55]\tBatch Time 2.825 (2.825)\tData Time 2.768 (2.768)\tLoss 1.9250 (1.9250)\t\n",
      "epoch: 258/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [258][0/55]\tBatch Time 2.922 (2.922)\tData Time 2.867 (2.867)\tLoss 3.2345 (3.2345)\t\n",
      "epoch: 259/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [259][0/55]\tBatch Time 2.897 (2.897)\tData Time 2.843 (2.843)\tLoss 3.5101 (3.5101)\t\n",
      "epoch: 260/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [260][0/55]\tBatch Time 2.863 (2.863)\tData Time 2.810 (2.810)\tLoss 3.5565 (3.5565)\t\n",
      "epoch: 261/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [261][0/55]\tBatch Time 2.822 (2.822)\tData Time 2.769 (2.769)\tLoss 3.1532 (3.1532)\t\n",
      "epoch: 262/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [262][0/55]\tBatch Time 2.849 (2.849)\tData Time 2.796 (2.796)\tLoss 2.7770 (2.7770)\t\n",
      "epoch: 263/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [263][0/55]\tBatch Time 2.857 (2.857)\tData Time 2.801 (2.801)\tLoss 3.9837 (3.9837)\t\n",
      "epoch: 264/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [264][0/55]\tBatch Time 2.960 (2.960)\tData Time 2.907 (2.907)\tLoss 2.4308 (2.4308)\t\n",
      "epoch: 265/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [265][0/55]\tBatch Time 2.889 (2.889)\tData Time 2.835 (2.835)\tLoss 4.1103 (4.1103)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 266/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [266][0/55]\tBatch Time 2.859 (2.859)\tData Time 2.806 (2.806)\tLoss 1.8309 (1.8309)\t\n",
      "epoch: 267/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [267][0/55]\tBatch Time 2.928 (2.928)\tData Time 2.874 (2.874)\tLoss 2.9065 (2.9065)\t\n",
      "epoch: 268/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [268][0/55]\tBatch Time 2.837 (2.837)\tData Time 2.781 (2.781)\tLoss 2.8324 (2.8324)\t\n",
      "epoch: 269/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [269][0/55]\tBatch Time 2.849 (2.849)\tData Time 2.794 (2.794)\tLoss 2.7451 (2.7451)\t\n",
      "epoch: 270/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [270][0/55]\tBatch Time 3.069 (3.069)\tData Time 3.017 (3.017)\tLoss 3.0272 (3.0272)\t\n",
      "epoch: 271/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [271][0/55]\tBatch Time 2.928 (2.928)\tData Time 2.873 (2.873)\tLoss 3.0378 (3.0378)\t\n",
      "epoch: 272/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [272][0/55]\tBatch Time 2.823 (2.823)\tData Time 2.770 (2.770)\tLoss 2.6535 (2.6535)\t\n",
      "epoch: 273/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [273][0/55]\tBatch Time 2.821 (2.821)\tData Time 2.767 (2.767)\tLoss 2.8570 (2.8570)\t\n",
      "epoch: 274/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [274][0/55]\tBatch Time 2.853 (2.853)\tData Time 2.798 (2.798)\tLoss 1.6388 (1.6388)\t\n",
      "epoch: 275/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [275][0/55]\tBatch Time 2.859 (2.859)\tData Time 2.803 (2.803)\tLoss 3.6109 (3.6109)\t\n",
      "epoch: 276/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [276][0/55]\tBatch Time 2.946 (2.946)\tData Time 2.892 (2.892)\tLoss 2.8316 (2.8316)\t\n",
      "epoch: 277/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [277][0/55]\tBatch Time 2.984 (2.984)\tData Time 2.926 (2.926)\tLoss 3.0659 (3.0659)\t\n",
      "epoch: 278/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [278][0/55]\tBatch Time 2.880 (2.880)\tData Time 2.822 (2.822)\tLoss 3.0705 (3.0705)\t\n",
      "epoch: 279/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [279][0/55]\tBatch Time 2.933 (2.933)\tData Time 2.881 (2.881)\tLoss 2.5639 (2.5639)\t\n",
      "epoch: 280/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [280][0/55]\tBatch Time 2.868 (2.868)\tData Time 2.816 (2.816)\tLoss 2.2400 (2.2400)\t\n",
      "epoch: 281/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [281][0/55]\tBatch Time 2.886 (2.886)\tData Time 2.829 (2.829)\tLoss 2.3808 (2.3808)\t\n",
      "epoch: 282/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [282][0/55]\tBatch Time 2.903 (2.903)\tData Time 2.851 (2.851)\tLoss 2.4627 (2.4627)\t\n",
      "epoch: 283/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [283][0/55]\tBatch Time 2.900 (2.900)\tData Time 2.845 (2.845)\tLoss 3.8196 (3.8196)\t\n",
      "epoch: 284/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [284][0/55]\tBatch Time 2.876 (2.876)\tData Time 2.822 (2.822)\tLoss 3.7481 (3.7481)\t\n",
      "epoch: 285/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [285][0/55]\tBatch Time 2.896 (2.896)\tData Time 2.843 (2.843)\tLoss 3.1213 (3.1213)\t\n",
      "epoch: 286/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [286][0/55]\tBatch Time 2.925 (2.925)\tData Time 2.871 (2.871)\tLoss 1.2545 (1.2545)\t\n",
      "epoch: 287/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [287][0/55]\tBatch Time 2.874 (2.874)\tData Time 2.818 (2.818)\tLoss 1.8659 (1.8659)\t\n",
      "epoch: 288/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [288][0/55]\tBatch Time 2.851 (2.851)\tData Time 2.793 (2.793)\tLoss 1.6769 (1.6769)\t\n",
      "epoch: 289/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [289][0/55]\tBatch Time 3.020 (3.020)\tData Time 2.967 (2.967)\tLoss 2.0771 (2.0771)\t\n",
      "epoch: 290/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [290][0/55]\tBatch Time 2.904 (2.904)\tData Time 2.851 (2.851)\tLoss 2.5784 (2.5784)\t\n",
      "epoch: 291/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [291][0/55]\tBatch Time 2.910 (2.910)\tData Time 2.857 (2.857)\tLoss 1.9191 (1.9191)\t\n",
      "epoch: 292/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [292][0/55]\tBatch Time 2.917 (2.917)\tData Time 2.863 (2.863)\tLoss 2.9065 (2.9065)\t\n",
      "epoch: 293/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [293][0/55]\tBatch Time 2.845 (2.845)\tData Time 2.792 (2.792)\tLoss 2.3414 (2.3414)\t\n",
      "epoch: 294/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [294][0/55]\tBatch Time 2.839 (2.839)\tData Time 2.785 (2.785)\tLoss 2.2931 (2.2931)\t\n",
      "epoch: 295/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [295][0/55]\tBatch Time 2.827 (2.827)\tData Time 2.769 (2.769)\tLoss 2.2063 (2.2063)\t\n",
      "epoch: 296/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [296][0/55]\tBatch Time 2.856 (2.856)\tData Time 2.803 (2.803)\tLoss 2.1645 (2.1645)\t\n",
      "epoch: 297/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [297][0/55]\tBatch Time 2.927 (2.927)\tData Time 2.869 (2.869)\tLoss 3.7969 (3.7969)\t\n",
      "epoch: 298/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [298][0/55]\tBatch Time 2.935 (2.935)\tData Time 2.882 (2.882)\tLoss 5.9417 (5.9417)\t\n",
      "epoch: 299/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [299][0/55]\tBatch Time 3.008 (3.008)\tData Time 2.953 (2.953)\tLoss 2.3037 (2.3037)\t\n",
      "epoch: 300/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [300][0/55]\tBatch Time 2.880 (2.880)\tData Time 2.825 (2.825)\tLoss 2.2255 (2.2255)\t\n",
      "epoch: 301/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [301][0/55]\tBatch Time 2.943 (2.943)\tData Time 2.888 (2.888)\tLoss 3.5649 (3.5649)\t\n",
      "epoch: 302/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [302][0/55]\tBatch Time 2.840 (2.840)\tData Time 2.786 (2.786)\tLoss 1.7834 (1.7834)\t\n",
      "epoch: 303/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [303][0/55]\tBatch Time 2.826 (2.826)\tData Time 2.771 (2.771)\tLoss 1.9835 (1.9835)\t\n",
      "epoch: 304/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [304][0/55]\tBatch Time 2.859 (2.859)\tData Time 2.798 (2.798)\tLoss 2.1940 (2.1940)\t\n",
      "epoch: 305/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [305][0/55]\tBatch Time 2.937 (2.937)\tData Time 2.885 (2.885)\tLoss 3.5927 (3.5927)\t\n",
      "epoch: 306/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [306][0/55]\tBatch Time 2.849 (2.849)\tData Time 2.789 (2.789)\tLoss 1.2809 (1.2809)\t\n",
      "epoch: 307/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [307][0/55]\tBatch Time 2.862 (2.862)\tData Time 2.810 (2.810)\tLoss 2.3081 (2.3081)\t\n",
      "epoch: 308/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [308][0/55]\tBatch Time 2.925 (2.925)\tData Time 2.872 (2.872)\tLoss 1.3595 (1.3595)\t\n",
      "epoch: 309/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [309][0/55]\tBatch Time 2.903 (2.903)\tData Time 2.849 (2.849)\tLoss 2.7174 (2.7174)\t\n",
      "epoch: 310/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [310][0/55]\tBatch Time 2.927 (2.927)\tData Time 2.873 (2.873)\tLoss 1.9642 (1.9642)\t\n",
      "epoch: 311/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [311][0/55]\tBatch Time 2.912 (2.912)\tData Time 2.855 (2.855)\tLoss 2.2148 (2.2148)\t\n",
      "epoch: 312/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [312][0/55]\tBatch Time 2.948 (2.948)\tData Time 2.895 (2.895)\tLoss 2.1984 (2.1984)\t\n",
      "epoch: 313/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [313][0/55]\tBatch Time 2.899 (2.899)\tData Time 2.846 (2.846)\tLoss 2.3493 (2.3493)\t\n",
      "epoch: 314/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [314][0/55]\tBatch Time 2.903 (2.903)\tData Time 2.845 (2.845)\tLoss 1.5682 (1.5682)\t\n",
      "epoch: 315/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [315][0/55]\tBatch Time 2.903 (2.903)\tData Time 2.846 (2.846)\tLoss 3.0537 (3.0537)\t\n",
      "epoch: 316/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [316][0/55]\tBatch Time 2.932 (2.932)\tData Time 2.880 (2.880)\tLoss 2.2527 (2.2527)\t\n",
      "epoch: 317/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [317][0/55]\tBatch Time 2.860 (2.860)\tData Time 2.807 (2.807)\tLoss 2.4608 (2.4608)\t\n",
      "epoch: 318/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [318][0/55]\tBatch Time 2.937 (2.937)\tData Time 2.884 (2.884)\tLoss 1.7008 (1.7008)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 319/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [319][0/55]\tBatch Time 2.852 (2.852)\tData Time 2.798 (2.798)\tLoss 2.5039 (2.5039)\t\n",
      "epoch: 320/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [320][0/55]\tBatch Time 2.957 (2.957)\tData Time 2.905 (2.905)\tLoss 3.5099 (3.5099)\t\n",
      "epoch: 321/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [321][0/55]\tBatch Time 2.923 (2.923)\tData Time 2.868 (2.868)\tLoss 2.0647 (2.0647)\t\n",
      "epoch: 322/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [322][0/55]\tBatch Time 2.891 (2.891)\tData Time 2.836 (2.836)\tLoss 1.8839 (1.8839)\t\n",
      "epoch: 323/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [323][0/55]\tBatch Time 2.831 (2.831)\tData Time 2.778 (2.778)\tLoss 1.2887 (1.2887)\t\n",
      "epoch: 324/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [324][0/55]\tBatch Time 2.857 (2.857)\tData Time 2.805 (2.805)\tLoss 1.6999 (1.6999)\t\n",
      "epoch: 325/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [325][0/55]\tBatch Time 2.865 (2.865)\tData Time 2.810 (2.810)\tLoss 1.7238 (1.7238)\t\n",
      "epoch: 326/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [326][0/55]\tBatch Time 2.855 (2.855)\tData Time 2.802 (2.802)\tLoss 2.9786 (2.9786)\t\n",
      "epoch: 327/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [327][0/55]\tBatch Time 2.889 (2.889)\tData Time 2.835 (2.835)\tLoss 2.1099 (2.1099)\t\n",
      "epoch: 328/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [328][0/55]\tBatch Time 2.882 (2.882)\tData Time 2.829 (2.829)\tLoss 2.2407 (2.2407)\t\n",
      "epoch: 329/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [329][0/55]\tBatch Time 2.854 (2.854)\tData Time 2.801 (2.801)\tLoss 2.4448 (2.4448)\t\n",
      "epoch: 330/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [330][0/55]\tBatch Time 2.941 (2.941)\tData Time 2.888 (2.888)\tLoss 1.9501 (1.9501)\t\n",
      "epoch: 331/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [331][0/55]\tBatch Time 3.013 (3.013)\tData Time 2.961 (2.961)\tLoss 1.8046 (1.8046)\t\n",
      "epoch: 332/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [332][0/55]\tBatch Time 2.963 (2.963)\tData Time 2.909 (2.909)\tLoss 2.4244 (2.4244)\t\n",
      "epoch: 333/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [333][0/55]\tBatch Time 2.930 (2.930)\tData Time 2.874 (2.874)\tLoss 1.8975 (1.8975)\t\n",
      "epoch: 334/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [334][0/55]\tBatch Time 2.911 (2.911)\tData Time 2.858 (2.858)\tLoss 2.2578 (2.2578)\t\n",
      "epoch: 335/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [335][0/55]\tBatch Time 2.892 (2.892)\tData Time 2.840 (2.840)\tLoss 1.7176 (1.7176)\t\n",
      "epoch: 336/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [336][0/55]\tBatch Time 2.930 (2.930)\tData Time 2.878 (2.878)\tLoss 3.0412 (3.0412)\t\n",
      "epoch: 337/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [337][0/55]\tBatch Time 2.869 (2.869)\tData Time 2.817 (2.817)\tLoss 2.0266 (2.0266)\t\n",
      "epoch: 338/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [338][0/55]\tBatch Time 3.050 (3.050)\tData Time 2.992 (2.992)\tLoss 2.0433 (2.0433)\t\n",
      "epoch: 339/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [339][0/55]\tBatch Time 2.876 (2.876)\tData Time 2.823 (2.823)\tLoss 1.9152 (1.9152)\t\n",
      "epoch: 340/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [340][0/55]\tBatch Time 2.916 (2.916)\tData Time 2.863 (2.863)\tLoss 1.6029 (1.6029)\t\n",
      "epoch: 341/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [341][0/55]\tBatch Time 2.873 (2.873)\tData Time 2.820 (2.820)\tLoss 1.3442 (1.3442)\t\n",
      "epoch: 342/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [342][0/55]\tBatch Time 2.859 (2.859)\tData Time 2.805 (2.805)\tLoss 1.4016 (1.4016)\t\n",
      "epoch: 343/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [343][0/55]\tBatch Time 2.851 (2.851)\tData Time 2.798 (2.798)\tLoss 1.6942 (1.6942)\t\n",
      "epoch: 344/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [344][0/55]\tBatch Time 2.854 (2.854)\tData Time 2.799 (2.799)\tLoss 2.8645 (2.8645)\t\n",
      "epoch: 345/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [345][0/55]\tBatch Time 2.877 (2.877)\tData Time 2.822 (2.822)\tLoss 2.9479 (2.9479)\t\n",
      "epoch: 346/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [346][0/55]\tBatch Time 2.923 (2.923)\tData Time 2.866 (2.866)\tLoss 1.6003 (1.6003)\t\n",
      "epoch: 347/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [347][0/55]\tBatch Time 2.991 (2.991)\tData Time 2.937 (2.937)\tLoss 1.5895 (1.5895)\t\n",
      "epoch: 348/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [348][0/55]\tBatch Time 3.002 (3.002)\tData Time 2.950 (2.950)\tLoss 2.2942 (2.2942)\t\n",
      "epoch: 349/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [349][0/55]\tBatch Time 2.914 (2.914)\tData Time 2.861 (2.861)\tLoss 2.3960 (2.3960)\t\n",
      "epoch: 350/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [350][0/55]\tBatch Time 2.864 (2.864)\tData Time 2.809 (2.809)\tLoss 1.7291 (1.7291)\t\n",
      "epoch: 351/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [351][0/55]\tBatch Time 2.961 (2.961)\tData Time 2.904 (2.904)\tLoss 2.0161 (2.0161)\t\n",
      "epoch: 352/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [352][0/55]\tBatch Time 2.856 (2.856)\tData Time 2.803 (2.803)\tLoss 1.9526 (1.9526)\t\n",
      "epoch: 353/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [353][0/55]\tBatch Time 3.301 (3.301)\tData Time 3.247 (3.247)\tLoss 1.3085 (1.3085)\t\n",
      "epoch: 354/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [354][0/55]\tBatch Time 3.050 (3.050)\tData Time 2.998 (2.998)\tLoss 1.2698 (1.2698)\t\n",
      "epoch: 355/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [355][0/55]\tBatch Time 2.984 (2.984)\tData Time 2.926 (2.926)\tLoss 1.3356 (1.3356)\t\n",
      "epoch: 356/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [356][0/55]\tBatch Time 2.956 (2.956)\tData Time 2.903 (2.903)\tLoss 2.0304 (2.0304)\t\n",
      "epoch: 357/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [357][0/55]\tBatch Time 2.853 (2.853)\tData Time 2.798 (2.798)\tLoss 1.3544 (1.3544)\t\n",
      "epoch: 358/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [358][0/55]\tBatch Time 2.928 (2.928)\tData Time 2.873 (2.873)\tLoss 1.8801 (1.8801)\t\n",
      "epoch: 359/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [359][0/55]\tBatch Time 2.842 (2.842)\tData Time 2.780 (2.780)\tLoss 1.8071 (1.8071)\t\n",
      "epoch: 360/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [360][0/55]\tBatch Time 2.872 (2.872)\tData Time 2.818 (2.818)\tLoss 1.4032 (1.4032)\t\n",
      "epoch: 361/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [361][0/55]\tBatch Time 2.879 (2.879)\tData Time 2.826 (2.826)\tLoss 1.1705 (1.1705)\t\n",
      "epoch: 362/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [362][0/55]\tBatch Time 2.935 (2.935)\tData Time 2.882 (2.882)\tLoss 1.4161 (1.4161)\t\n",
      "epoch: 363/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [363][0/55]\tBatch Time 2.808 (2.808)\tData Time 2.756 (2.756)\tLoss 1.3694 (1.3694)\t\n",
      "epoch: 364/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [364][0/55]\tBatch Time 2.833 (2.833)\tData Time 2.775 (2.775)\tLoss 2.1655 (2.1655)\t\n",
      "epoch: 365/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [365][0/55]\tBatch Time 2.918 (2.918)\tData Time 2.862 (2.862)\tLoss 2.0470 (2.0470)\t\n",
      "epoch: 366/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [366][0/55]\tBatch Time 2.858 (2.858)\tData Time 2.803 (2.803)\tLoss 1.2063 (1.2063)\t\n",
      "epoch: 367/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [367][0/55]\tBatch Time 2.930 (2.930)\tData Time 2.877 (2.877)\tLoss 1.6230 (1.6230)\t\n",
      "epoch: 368/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [368][0/55]\tBatch Time 2.928 (2.928)\tData Time 2.874 (2.874)\tLoss 1.5996 (1.5996)\t\n",
      "epoch: 369/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [369][0/55]\tBatch Time 3.233 (3.233)\tData Time 3.181 (3.181)\tLoss 2.0927 (2.0927)\t\n",
      "epoch: 370/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [370][0/55]\tBatch Time 2.964 (2.964)\tData Time 2.911 (2.911)\tLoss 1.3872 (1.3872)\t\n",
      "epoch: 371/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [371][0/55]\tBatch Time 2.837 (2.837)\tData Time 2.782 (2.782)\tLoss 1.0694 (1.0694)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 372/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [372][0/55]\tBatch Time 2.932 (2.932)\tData Time 2.880 (2.880)\tLoss 1.6243 (1.6243)\t\n",
      "epoch: 373/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [373][0/55]\tBatch Time 3.133 (3.133)\tData Time 3.080 (3.080)\tLoss 3.2312 (3.2312)\t\n",
      "epoch: 374/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [374][0/55]\tBatch Time 2.951 (2.951)\tData Time 2.899 (2.899)\tLoss 2.2884 (2.2884)\t\n",
      "epoch: 375/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [375][0/55]\tBatch Time 2.865 (2.865)\tData Time 2.812 (2.812)\tLoss 1.3294 (1.3294)\t\n",
      "epoch: 376/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [376][0/55]\tBatch Time 2.929 (2.929)\tData Time 2.874 (2.874)\tLoss 1.4102 (1.4102)\t\n",
      "epoch: 377/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [377][0/55]\tBatch Time 2.839 (2.839)\tData Time 2.785 (2.785)\tLoss 1.3710 (1.3710)\t\n",
      "epoch: 378/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [378][0/55]\tBatch Time 2.959 (2.959)\tData Time 2.904 (2.904)\tLoss 1.5383 (1.5383)\t\n",
      "epoch: 379/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [379][0/55]\tBatch Time 2.897 (2.897)\tData Time 2.838 (2.838)\tLoss 0.9859 (0.9859)\t\n",
      "epoch: 380/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [380][0/55]\tBatch Time 2.887 (2.887)\tData Time 2.833 (2.833)\tLoss 1.1796 (1.1796)\t\n",
      "epoch: 381/382\n",
      "torch.Size([2, 8732, 4])\n",
      "torch.Size([2, 8732, 3])\n",
      "Epoch: [381][0/55]\tBatch Time 2.921 (2.921)\tData Time 2.860 (2.860)\tLoss 1.6824 (1.6824)\t\n"
     ]
    }
   ],
   "source": [
    "state = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {'epoch': state[0],\n",
    "             'model': state[1],\n",
    "             'optimizer': state[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 381,\n",
       " 'model': SSD300(\n",
       "   (base): VGGBase(\n",
       "     (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "     (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (pool5): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "     (conv6): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "     (conv7): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "   )\n",
       "   (aux_convs): AuxiliaryConvolutions(\n",
       "     (conv8_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "     (conv8_2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "     (conv9_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "     (conv9_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "     (conv10_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "     (conv10_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (conv11_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "     (conv11_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "   )\n",
       "   (pred_convs): PredictionConvolutions(\n",
       "     (loc_conv4_3): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (loc_conv7): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (loc_conv8_2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (loc_conv9_2): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (loc_conv10_2): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (loc_conv11_2): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (cl_conv4_3): Conv2d(512, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (cl_conv7): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (cl_conv8_2): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (cl_conv9_2): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (cl_conv10_2): Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (cl_conv11_2): Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   )\n",
       " ),\n",
       " 'optimizer': SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     lr: 0.002\n",
       "     momentum: 0.9\n",
       "     nesterov: False\n",
       "     weight_decay: 0.0005\n",
       " \n",
       " Parameter Group 1\n",
       "     dampening: 0\n",
       "     lr: 0.001\n",
       "     momentum: 0.9\n",
       "     nesterov: False\n",
       "     weight_decay: 0.0005\n",
       " )}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(state, 'checkpoint_fede.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
